{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5c4fc3-3a4e-4ea3-9b09-dc4d37a7114e",
   "metadata": {},
   "source": [
    "A while ago I had an idea for an optimization algorithm which uses a \"local\" search heuristic and a \"global\" search heuristic and switches between them automatically depending on how long it has been since each algorithm has seen an improvement. That way we don't waste time exploring new points with random search when we've clearly found a good reigon we should exploit with SGD, and similarly we don't let SGD just fall to a local optimum and then sit there doing nothing when we could explore with RS.\n",
    "\n",
    "The heuristic of \"switch to an algorithm with probability proportional to its rate of improvement\" is a good enough heuristic but probably isn't quite optimal (win-stay-lose-switch performs well on multi-armed bandits, maybe that could work here?) but in this code I'm curious about using human control with multithreading. The human has access to a a GUI which shows an updating graph of the best loss over time. At any point the human can enter the command \"S\" for \"Switch\" and the algoritm will switch to the other search heuristic. Similarly they can enter \"L\" for the \"left\" heuristic and \"R\" for the \"right\" one. The point is, does a human-controlled two-handed optimizer beat the current switching heuristic? How does it compare to win-stay-lose-switch?\n",
    "\n",
    "We're assuming that the bottle neck is *objective function calls* here rather than time itself. Maybe it's just really expensive (in terms of time, money, or some other important resource) to call the objective function. We have to slow the HCTH to give the human enough time to respond so it will perform worse in terms of runtime, but possibly better in terms of objective function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6d807-fef2-4ec0-b073-72e374db42b5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438a2fed-d769-4e86-815f-99b11625a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "\n",
    "#For GUI construction\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8431e7b-9b87-45b8-aafe-a94685a8575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many iterations the algorithms get\n",
    "numIt = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ca7e4-c4d2-4658-a99d-69eb435105ff",
   "metadata": {},
   "source": [
    "#### Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585782a-ba82-4722-a6c2-6e3d0ed77d00",
   "metadata": {},
   "source": [
    "Michalewicz is an interesting optimization function. It has a large number of local minima, which can cause algorithms to become trapped in local minima. It can also be defined on any number of dimensions, which makes it an interesting function for high-dimensional optimization problems.\n",
    "\n",
    "Reference: https://www.sfu.ca/~ssurjano/michal.html\n",
    "\n",
    "In this task we'll maximize -1 times Michalewicz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99ecc37-9fea-4fc8-9e9d-c175680792a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowBound = 0\n",
    "highBound = np.pi\n",
    "numDimensions = 10 #Usually 10+, but 2 is better for plotting\n",
    "trigPower = 10 #\"m\" in the definition\n",
    "ranges = []\n",
    "for i in range(numDimensions):\n",
    "    ranges.append([-lowBound, highBound])\n",
    "#Note: global minima values are known for some specific values of trigPower\n",
    "\n",
    "def michalewicz(x):\n",
    "    output = 0\n",
    "    for i in range(len(x)):\n",
    "        output -= np.sin(x[i]) * (np.sin((i + 1) * (x[i] ** 2) / np.pi)) ** (2 * trigPower)\n",
    "    return(output)\n",
    "\n",
    "def objective(x):\n",
    "    return(-michalewicz(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f6725-7659-4b49-95e0-5c31f95eb98c",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4021a6-9c14-44f7-9395-3a9e0d71d4f0",
   "metadata": {},
   "source": [
    "### Automated Two-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b66089-237c-4a8c-b794-8d5d27309ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHanded:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ranges,\n",
    "        leftPoints = 1,\n",
    "        rightPoints = 1\n",
    "    ):\n",
    "        self.ranges = ranges\n",
    "        self.leftPoints = leftPoints\n",
    "        self.rightPoints = rightPoints\n",
    "\n",
    "        #GUI Graph\n",
    "        self.bestHistory = []\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlabel(\"Iteration\")\n",
    "        self.ax.set_ylabel(\"Best objective value so far\")\n",
    "        self.line, = self.ax.plot([], [], \"b-\")\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "\n",
    "    def _updateGraph(self):\n",
    "        self.line.set_xdata(list(range(len(self.bestHistory))))\n",
    "        self.line.set_ydata(self.bestHistory)\n",
    "        self.ax.relim()\n",
    "        self.ax.autoscale_view()\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "    def selectLeftOrRight(self):\n",
    "        probLeft = self.leftPoints / (self.leftPoints + self.rightPoints)\n",
    "        if r.uniform(0, 1) < probLeft:\n",
    "            return(\"L\")\n",
    "        else:\n",
    "            return(\"R\")\n",
    "\n",
    "    #Random search's hypothesis selector.\n",
    "    def generateRandomHypothesis(self):\n",
    "        output = []\n",
    "        for x in self.ranges:\n",
    "            output.append(r.uniform(x[0], x[1]))\n",
    "        return(output)\n",
    "\n",
    "    #One iteration of gradient descent\n",
    "    def gradientStep(self, objectiveFunction, currentX, dx = 10 ** (-10),\n",
    "                     learnRate = 0.01):\n",
    "        gradientVector = []\n",
    "        for i in range(len(currentX)):\n",
    "            cloneX = [x for x in currentX]\n",
    "            Y1 = objectiveFunction(cloneX)\n",
    "            cloneX[i] += dx\n",
    "            Y2 = objectiveFunction(cloneX)\n",
    "            gradientVector.append((Y2 - Y1)/dx)\n",
    "        outputX = [x for x in currentX]\n",
    "        for i in range(len(outputX)):\n",
    "            outputX[i] += gradientVector[i] * learnRate\n",
    "        return(outputX)\n",
    "\n",
    "    def optimize(self, objectiveFunction, numIterations = numIt):\n",
    "        currentX = [np.mean(x) for x in self.ranges]\n",
    "        currentY = objectiveFunction(currentX)\n",
    "\n",
    "        for i in range(numIterations):\n",
    "            leftRightDecision = self.selectLeftOrRight()\n",
    "\n",
    "            if leftRightDecision == \"L\":\n",
    "                newX = self.generateRandomHypothesis()\n",
    "                newY = objectiveFunction(newX)\n",
    "\n",
    "                if newY > currentY:\n",
    "                    currentY = newY\n",
    "                    currentX = newX\n",
    "                    self.leftPoints += 1\n",
    "                else:\n",
    "                    self.rightPoints += 1\n",
    "\n",
    "            else:\n",
    "                if currentX == None:\n",
    "                    currentX = [np.mean(x) for x in self.ranges]\n",
    "\n",
    "                newX = self.gradientStep(objectiveFunction, currentX)\n",
    "                newY = objectiveFunction(newX)\n",
    "\n",
    "                if newY > currentY:\n",
    "                    currentY = newY\n",
    "                    currentX = newX\n",
    "                    self.rightPoints += 1\n",
    "                else:\n",
    "                    self.leftPoints += 1\n",
    "\n",
    "            #Update graph\n",
    "            self.bestHistory.append(currentY)\n",
    "            self._updateGraph()\n",
    "\n",
    "        return(currentX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e04cb-5de0-480a-8ba1-9087ca77bd53",
   "metadata": {},
   "source": [
    "### Human-Controlled Two-Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb117a44-53cc-49e4-b46a-07adec2d283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanControlledTwoHanded:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ranges,\n",
    "        leftPoints = 1,\n",
    "        rightPoints = 1\n",
    "    ):\n",
    "        self.ranges = ranges\n",
    "        self.leftPoints = leftPoints\n",
    "        self.rightPoints = rightPoints\n",
    "\n",
    "        self.bestHistory = []\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlabel(\"Iteration\")\n",
    "        self.ax.set_ylabel(\"Best objective value so far\")\n",
    "        self.line, = self.ax.plot([], [], \"b-\")\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "\n",
    "        self.humanCommand = None\n",
    "        self.running = True\n",
    "        self.currentChoice = \"L\"\n",
    "\n",
    "        self.speed = 1\n",
    "\n",
    "        self.inputThread = threading.Thread(target=self._listenForInput)\n",
    "        self.inputThread.daemon = True\n",
    "        self.inputThread.start()\n",
    "\n",
    "    def _listenForInput(self):\n",
    "        while self.running:\n",
    "            cmd = input().strip().lower()\n",
    "            if cmd in [\"s\", \"l\", \"r\", \"x\"]:\n",
    "                self.humanCommand = cmd\n",
    "            elif len(cmd) == 1 and cmd.isdigit():\n",
    "                self.humanCommand = cmd\n",
    "\n",
    "    def _updateGraph(self):\n",
    "        self.line.set_xdata(list(range(len(self.bestHistory))))\n",
    "        self.line.set_ydata(self.bestHistory)\n",
    "        self.ax.relim()\n",
    "        self.ax.autoscale_view()\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "    def _applyHumanCommand(self):\n",
    "        if self.humanCommand == None:\n",
    "            return\n",
    "\n",
    "        if self.humanCommand == \"x\":\n",
    "            self.running = False\n",
    "\n",
    "        elif self.humanCommand == \"s\":\n",
    "            if self.currentChoice == \"L\":\n",
    "                self.currentChoice = \"R\"\n",
    "            else:\n",
    "                self.currentChoice = \"L\"\n",
    "\n",
    "        elif self.humanCommand == \"l\":\n",
    "            self.currentChoice = \"L\"\n",
    "\n",
    "        elif self.humanCommand == \"r\":\n",
    "            self.currentChoice = \"R\"\n",
    "\n",
    "        elif self.humanCommand.isdigit():\n",
    "            self.speed = int(self.humanCommand)\n",
    "\n",
    "        self.humanCommand = None\n",
    "\n",
    "    def generateRandomHypothesis(self):\n",
    "        output = []\n",
    "        for x in self.ranges:\n",
    "            output.append(r.uniform(x[0], x[1]))\n",
    "        return(output)\n",
    "\n",
    "    def gradientStep(self, objectiveFunction, currentX, dx = 10 ** (-10),\n",
    "                     learnRate = 0.01):\n",
    "        gradientVector = []\n",
    "        for i in range(len(currentX)):\n",
    "            cloneX = [x for x in currentX]\n",
    "            Y1 = objectiveFunction(cloneX)\n",
    "            cloneX[i] += dx\n",
    "            Y2 = objectiveFunction(cloneX)\n",
    "            gradientVector.append((Y2 - Y1)/dx)\n",
    "        outputX = [x for x in currentX]\n",
    "        for i in range(len(outputX)):\n",
    "            outputX[i] += gradientVector[i] * learnRate\n",
    "        return(outputX)\n",
    "\n",
    "    def optimize(self, objectiveFunction, numIterations = numIt):\n",
    "        currentX = [np.mean(x) for x in self.ranges]\n",
    "        currentY = objectiveFunction(currentX)\n",
    "\n",
    "        for i in range(numIterations):\n",
    "            if not self.running:\n",
    "                break\n",
    "\n",
    "            self._applyHumanCommand()\n",
    "\n",
    "            if self.currentChoice == \"L\":\n",
    "                newX = self.generateRandomHypothesis()\n",
    "                newY = objectiveFunction(newX)\n",
    "\n",
    "                if newY > currentY:\n",
    "                    currentY = newY\n",
    "                    currentX = newX\n",
    "\n",
    "            else:\n",
    "                newX = self.gradientStep(objectiveFunction, currentX)\n",
    "                newY = objectiveFunction(newX)\n",
    "\n",
    "                if newY > currentY:\n",
    "                    currentY = newY\n",
    "                    currentX = newX\n",
    "\n",
    "            self.bestHistory.append(currentY)\n",
    "            self._updateGraph()\n",
    "\n",
    "            time.sleep(max(0, 1 - 0.1 * self.speed))\n",
    "\n",
    "        self.running = False\n",
    "        return(currentX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc72536-4681-4e12-8084-17958b70d5b1",
   "metadata": {},
   "source": [
    "### Win-Stay-Lose-Switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130d53f2-5273-4ea0-be46-d511c0442178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHandedWSLS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ranges,\n",
    "        leftPoints = 1,\n",
    "        rightPoints = 1\n",
    "    ):\n",
    "        self.ranges = ranges\n",
    "        self.leftPoints = leftPoints\n",
    "        self.rightPoints = rightPoints\n",
    "\n",
    "        self.bestHistory = []\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlabel(\"Iteration\")\n",
    "        self.ax.set_ylabel(\"Best objective value so far\")\n",
    "        self.line, = self.ax.plot([], [], \"b-\")\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "\n",
    "        self.currentChoice = \"L\"\n",
    "\n",
    "    def _updateGraph(self):\n",
    "        self.line.set_xdata(list(range(len(self.bestHistory))))\n",
    "        self.line.set_ydata(self.bestHistory)\n",
    "        self.ax.relim()\n",
    "        self.ax.autoscale_view()\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "    def generateRandomHypothesis(self):\n",
    "        output = []\n",
    "        for x in self.ranges:\n",
    "            output.append(r.uniform(x[0], x[1]))\n",
    "        return(output)\n",
    "\n",
    "    def gradientStep(self, objectiveFunction, currentX, dx = 10 ** (-10),\n",
    "                     learnRate = 0.01):\n",
    "        gradientVector = []\n",
    "        for i in range(len(currentX)):\n",
    "            cloneX = [x for x in currentX]\n",
    "            Y1 = objectiveFunction(cloneX)\n",
    "            cloneX[i] += dx\n",
    "            Y2 = objectiveFunction(cloneX)\n",
    "            gradientVector.append((Y2 - Y1)/dx)\n",
    "        outputX = [x for x in currentX]\n",
    "        for i in range(len(outputX)):\n",
    "            outputX[i] += gradientVector[i] * learnRate\n",
    "        return(outputX)\n",
    "\n",
    "    def optimize(self, objectiveFunction, numIterations = numIt):\n",
    "        currentX = [np.mean(x) for x in self.ranges]\n",
    "        currentY = objectiveFunction(currentX)\n",
    "\n",
    "        for i in range(numIterations):\n",
    "            if self.currentChoice == \"L\":\n",
    "                newX = self.generateRandomHypothesis()\n",
    "                newY = objectiveFunction(newX)\n",
    "            else:\n",
    "                newX = self.gradientStep(objectiveFunction, currentX)\n",
    "                newY = objectiveFunction(newX)\n",
    "\n",
    "            if newY > currentY:\n",
    "                currentY = newY\n",
    "                currentX = newX\n",
    "            else:\n",
    "                if self.currentChoice == \"L\":\n",
    "                    self.currentChoice = \"R\"\n",
    "                else:\n",
    "                    self.currentChoice = \"L\"\n",
    "\n",
    "            self.bestHistory.append(currentY)\n",
    "            self._updateGraph()\n",
    "\n",
    "        return(currentX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2779a-a53d-49f8-9c34-f629684a1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome!\n",
      "The commands are:\n",
      "l: switch to random search\n",
      "r: switch to gradient decent\n",
      "s: switch to whichever algorithm is not being used\n",
      "0-9: set the speed\n",
      "x: end the optimization process early\n",
      "Press any key to continue!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " w\n",
      " l\n",
      " s\n",
      " 9\n",
      " l\n",
      " r\n",
      " l\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome!\")\n",
    "print(\"The commands are:\")\n",
    "print(\"l: switch to random search\")\n",
    "print(\"r: switch to gradient decent\")\n",
    "print(\"s: switch to whichever algorithm is not being used\")\n",
    "print(\"0-9: set the speed\")\n",
    "print(\"x: end the optimization process early\")\n",
    "print(\"Press any key to continue!\")\n",
    "user_responsive = input()\n",
    "th_human = HumanControlledTwoHanded(ranges)\n",
    "print(th_human.optimize(objective))\n",
    "\n",
    "th = TwoHanded(ranges)\n",
    "print(th.optimize(objective))\n",
    "\n",
    "th_wsls = TwoHandedWSLS(ranges)\n",
    "print(th_wsls.optimize(objective))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
